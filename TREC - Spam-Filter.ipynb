{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam-Filter mit Bayes\n",
    "\n",
    "Die [Text REtrieval Conference (TREC) Spam Track Konferenz](https://trec.nist.gov/pubs/trec16/papers/SPAM.OVERVIEW16.pdf) im Jahr 2007 hatte das Ziel die Erkennung vom SPAM-Nachrichten zu verbessern.\n",
    "\n",
    "Um die Methoden zu evaluieren wurde ein [Datensatz](http://plg.uwaterloo.ca/~gvcormac/treccorpus07/) aus 75419 E-Mails verwendet. Die Daten bestehen aus 25220 Nicht-SPAM-Nachrichten und 50199 SPAM-Nachrichten. Die E-Mails wurden dabei zwischen dem 8. April und 6 Juli 2007 auf einem E-Mail-Server gesammelt.\n",
    "\n",
    "Wir wollen einen Filter bauen, der eine Email an Hand Ihres Betreffs und Korpus als *Spam* oder *kein-Spam* klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Spam-Mails: 50199\n",
      "Anzahl der No-Spam-Mails: 25220\n"
     ]
    }
   ],
   "source": [
    "# wir laden die Daten\n",
    "import email\n",
    "\n",
    "nospam, spam = [], []\n",
    "with open('../Daten/trec07p/full/index','r') as fin:\n",
    "    for line in fin:\n",
    "        classification, fn = line.strip().split(' ')\n",
    "        with open('../Daten/trec07p/full/'+fn, errors='ignore') as fin:\n",
    "            if classification == 'ham':\n",
    "                nospam.append(email.message_from_file(fin))\n",
    "            elif classification == 'spam':\n",
    "                spam.append(email.message_from_file(fin))\n",
    "            else:\n",
    "                raise 'ERROR: Unknown Classifikation: %s' % classification\n",
    "            \n",
    "print('Anzahl der Spam-Mails: %d' % len(spam))\n",
    "print('Anzahl der No-Spam-Mails: %d' % len(nospam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Als nächstes werden aus den Betreffs und E-Mail-Texten Wortlisten, wobei Sonderzeichen und Zahlen ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "stopwords = ('and', 'further', 'he', 'with', 'those', 're', 'to', \"she's\", 'same', 'this', 'only', 'its', 'but', 'both', 'him', 'too', 'himself', 'them', 'any', \"you'll\", 'from', 'here', \"don't\", 'we', 'you', 'yourselves', 'between', 'been', \"won't\", 'after', 'theirs', 'most', 'shan', 'i', 'nor', 'below', 'do', 'd', 'should', 'which', 'under', 'her', 'am', \"needn't\", \"wouldn't\", 'their', 'what', 'have', 'me', 'during', 'just', 'is', 'where', \"wasn't\", 'when', 'all', 'themselves', 'few', 'now', 't', 'in', \"couldn't\", \"hasn't\", 'ma', 'into', 'she', 'other', 'my', 'did', 'll', 'no', 'wouldn', 'some', 'such', 'out', 'aren', 'a', \"didn't\", 'ours', 'having', 'an', 'shouldn', 'hasn', 'off', 'didn', 'against', 'ourselves', 'doing', 'again', 'ain', 'the', 'if', 'were', 'as', \"mustn't\", 'at', 'by', 'couldn', 'itself', 'your', 'before', 'each', \"you're\", 'has', \"isn't\", \"shan't\", 'they', 'herself', 'y', \"haven't\", 'needn', 'his', 'because', 'own', \"you've\", 's', \"you'd\", \"that'll\", \"aren't\", \"weren't\", 'more', 'whom', 'being', \"doesn't\", 'then', 'does', 'so', 'while', 'why', 'who', 'once', 'will', 'isn', 'weren', \"should've\", 'mustn', 'won', 'be', 'hers', 'had', \"shouldn't\", 'about', 'or', 'above', 'there', 'o', 'doesn', \"mightn't\", 'over', \"hadn't\", 'wasn', 'was', 'hadn', 'up', 'yourself', 've', 'our', 'can', 'on', 'm', 'for', 'very', 'myself', 'of', 'don', 'haven', 'how', 'yours', 'through', 'until', 'these', 'that', \"it's\", 'are', 'than', 'it', 'mightn', 'not', 'down')\n",
    "\n",
    "def nachr2str(parts):\n",
    "    ret = ''\n",
    "    if type(parts) == str:\n",
    "        ret += \" \" + parts\n",
    "    elif type(parts) == list:\n",
    "        for part in parts:\n",
    "            ret += nachr2str(part.get_payload())\n",
    "    elif parts.get_content_type == 'text/plain':\n",
    "        ret += parts.get_payload()\n",
    "    return ret\n",
    "\n",
    "def extrahiere_woerter(mail):\n",
    "    betreff = mail['Subject']\n",
    "    if not betreff:\n",
    "        betreff = ''\n",
    "    text = betreff + ' ' + nachr2str(mail.get_payload())\n",
    "    # extrahiere Wörter, mach aus einem Betreff und Text eine Wortliste aus Kleinbuchstachen ohne Duplikate\n",
    "    tokens = set(re.findall('[^\\W\\d]+', text.lower()))\n",
    "\n",
    "    # bilde den Wortstamm und entferne Stoppwörter\n",
    "    return set([stemmer.stem(w) for w in tokens if w not in stopwords])\n",
    "\n",
    "spam_wortlisten = []\n",
    "nospam_wortlisten = []\n",
    "for mail in nospam:\n",
    "    nospam_wortlisten.append(extrahiere_woerter(mail))\n",
    "for mail in spam:\n",
    "    spam_wortlisten.append(extrahiere_woerter(mail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gr', 'margin', 'com', 'bodi', 'ffff', 'px', 'tr', 'pressur', 'v', 'b', 'align', 'html', 'past', 'excoriationtuh', 'bottom', 'border', 'width', 'ffffff', 'back', 'rise', 'bgcolor', 'cellspac', 'color', 'ccffaa', 'brand', 'center', 'ciali', 'qualiti', 'tri', 'td', 'br', 'feel', 'http', 'gener', 'div', 'right', 'self', 'solid', 'tabl', 'style', 'span', 'anxieti', 'cellpad', 'ia', 'href', 'occas', 'perform', 'old', 'thing', 'lzmfnrdklek'}\n",
      "{'pass', 'com', 'seem', 'fr', 'listmast', 'unstabl', 'autom', 'org', 'releas', 'like', 'replac', 'list', 'html', 'en', 'hi', 'etch', 'readm', 'littl', 'libr', 'unsubscrib', 'name', 'updat', 'savoirfairelinux', 'lenni', 'logiciel', 'contact', 'develop', 'mirror', 'yan', 'propog', 'ftp', 'gulu', 'subject', 'http', 'dist', 'consult', 'ca', 'request', 'troubl', 'usherbrook', 'current', 'exampl', 'typo', 'email', 'file', 'test', 'debian', 'check', 'packag', 'snapshot', 'morin', 'access'}\n"
     ]
    }
   ],
   "source": [
    "print(spam_wortlisten[0])\n",
    "print(nospam_wortlisten[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70% der Daten sollen für das Training und die anderen für den Test benutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(4711)\n",
    "\n",
    "# verwürfle die Listen\n",
    "random.shuffle(spam_wortlisten)\n",
    "random.shuffle(nospam_wortlisten)\n",
    "\n",
    "# 70% der Daten sollen zum Training die anderen 30% zum Testen genutzt werden\n",
    "m = 70\n",
    "train_spam, test_spam = spam_wortlisten[:m*len(spam_wortlisten)//100], spam_wortlisten[m*len(spam_wortlisten)//100:]\n",
    "train_nospam, test_nospam = nospam_wortlisten[:m*len(nospam_wortlisten)//100], nospam_wortlisten[m*len(nospam_wortlisten)//100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wir bauen nun den Bayes-Klassifizierer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "N_Spam = len(train_spam)\n",
    "N_NoSpam = len(train_nospam)\n",
    "\n",
    "wortliste_spam, wortliste_nospam = defaultdict(int), defaultdict(int)\n",
    "\n",
    "for wortliste in train_spam:\n",
    "    for wort in wortliste:\n",
    "        wortliste_spam[wort] += 1\n",
    "        \n",
    "for wortliste in train_nospam:\n",
    "    for wort in wortliste:\n",
    "        wortliste_nospam[wort] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Der Klassifizierer\n",
    "\n",
    "Jetzt haben wir die Häufigkeiten/Wahrscheinlichkeiten, um unbekannte Nachrichten zu klassifizieren:\n",
    "\n",
    "$$ \\frac{P(\\text{Spam} \\;|\\; w_1 \\land \\ldots \\land w_n)}{P(\\overline{\\text{Spam}} \\;|\\; w_1 \\land \\ldots \\land w_n)}  = \\left( \\prod_{i=1}^n \\frac{N_{\\text{Spam}, w_i}+1}{N_{\\text{Spam}}+2}\\right) \\cdot \\left( \\prod_{i=1}^n \\frac{N_{\\overline{\\text{Spam}}, w_i}+1}{N_{\\overline{\\text{Spam}}}+2}\\right)^{-1} \\cdot \\frac{N_{\\text{Spam}}+2}{N_{\\overline{\\text{Spam}}}+2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           erkannt (%)    nicht erkannt (%)\n",
      "-------------------------------------------\n",
      "Spam:       14449  95.9            611   4.1\n",
      "No-Spam:    7511  99.3             55   0.7\n",
      "Insgesamt:  21960  97.1            666   2.9\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "def klassifiziereBetreff(wortliste):\n",
    "    return ((N_Spam+2)/(N_NoSpam+2)) * reduce(mul, [((wortliste_spam[wort]+1)/(N_Spam+2)) / ((wortliste_nospam[wort]+1)/(N_NoSpam+2)) for wort in wortliste], 1)\n",
    "\n",
    "schwelle = 1  # Klassifizierungsschwellwert\n",
    "\n",
    "korrekt_spam = fehler_spam = 0\n",
    "for wortliste in test_spam:\n",
    "    if klassifiziereBetreff(wortliste) >= schwelle:\n",
    "        korrekt_spam += 1\n",
    "    else:\n",
    "        fehler_spam += 1\n",
    "\n",
    "korrekt_nospam = fehler_nospam = 0\n",
    "for wortliste in test_nospam:\n",
    "    if klassifiziereBetreff(wortliste) >= schwelle:\n",
    "        fehler_nospam += 1\n",
    "    else:\n",
    "        korrekt_nospam += 1\n",
    "\n",
    "print('           erkannt (%)    nicht erkannt (%)')\n",
    "print('-'*43)\n",
    "print('Spam:       {0:4d} {1:5.01f}           {2:4d} {3:5.01f}'.format(korrekt_spam, korrekt_spam*100/len(test_spam), fehler_spam, fehler_spam*100/len(test_spam)))\n",
    "print('No-Spam:    {0:4d} {1:5.01f}           {2:4d} {3:5.01f}'.format(korrekt_nospam, korrekt_nospam*100/len(test_nospam), fehler_nospam, fehler_nospam*100/len(test_nospam)))\n",
    "print('Insgesamt:  {0:4d} {1:5.01f}           {2:4d} {3:5.01f}'.format(korrekt_spam+korrekt_nospam, (korrekt_spam+korrekt_nospam)*100/(len(test_spam)+len(test_nospam)), fehler_spam+fehler_nospam, (fehler_spam+fehler_nospam)*100/(len(test_spam)+len(test_nospam))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
